#!/usr/bin/env python3
"""
Analyze the quality improvement of the precise extraction approach.
"""

import sqlite3
import json
from typing import Dict, List, Tuple
import statistics
import re

def analyze_precise_database():
    """Analyze the new precise extraction database quality."""
    db_path = "curriculum_precise.db"
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Check table schema
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        print(f"üìã Found {len(tables)} tables: {[t[0] for t in tables]}")
        
        # Analyze lessons table
        cursor.execute("SELECT COUNT(*) FROM lessons")
        total_lessons = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM lessons WHERE extraction_confidence >= 0.7")
        high_confidence = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(LENGTH(content)) FROM lessons")
        avg_content_length = cursor.fetchone()[0] or 0
        
        cursor.execute("SELECT COUNT(*) FROM lessons WHERE LENGTH(content) > 1000")
        substantial_content = cursor.fetchone()[0]
        
        # Quality by grade/version
        cursor.execute("""
        SELECT grade, version, COUNT(*) as lesson_count, 
               AVG(extraction_confidence) as avg_confidence,
               COUNT(CASE WHEN extraction_confidence >= 0.7 THEN 1 END) as high_quality,
               AVG(LENGTH(content)) as avg_content_length
        FROM lessons 
        GROUP BY grade, version 
        ORDER BY grade, version
        """)
        grade_analysis = cursor.fetchall()
        
        # Sample some lesson content for quality assessment
        cursor.execute("""
        SELECT title, content, standards, extraction_confidence 
        FROM lessons 
        WHERE extraction_confidence >= 0.7 
        ORDER BY RANDOM() 
        LIMIT 5
        """)
        sample_lessons = cursor.fetchall()
        
        # Standards coverage
        cursor.execute("SELECT COUNT(DISTINCT standards) FROM lessons WHERE standards IS NOT NULL AND standards != ''")
        unique_standards = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM lessons WHERE standards IS NOT NULL AND standards != ''")
        lessons_with_standards = cursor.fetchone()[0]
        
        print(f"\nüéØ PRECISION EXTRACTION QUALITY ANALYSIS")
        print("=" * 60)
        print(f"üìä Total Lessons: {total_lessons}")
        print(f"üéØ High Confidence (‚â•0.7): {high_confidence} ({high_confidence/total_lessons*100:.1f}%)")
        print(f"üìù Average Content Length: {avg_content_length:.0f} chars")
        print(f"üìö Substantial Content (>1000 chars): {substantial_content} ({substantial_content/total_lessons*100:.1f}%)")
        print(f"üè∑Ô∏è Standards Coverage: {lessons_with_standards}/{total_lessons} lessons ({lessons_with_standards/total_lessons*100:.1f}%)")
        print(f"üìã Unique Standards: {unique_standards}")
        
        print(f"\nüìà BY GRADE/VERSION:")
        for grade, version, count, conf, hq, content_len in grade_analysis:
            print(f"   Grade {grade} V{version}: {count} lessons, {conf:.2f} confidence, {hq} high-quality ({hq/count*100:.1f}%), {content_len:.0f} chars avg")
        
        # Calculate overall quality score
        content_quality = min(100, (avg_content_length / 2000) * 100)  # Scale to 2000 chars as excellent
        confidence_quality = (high_confidence / total_lessons) * 100
        standards_quality = (lessons_with_standards / total_lessons) * 100
        
        overall_score = (content_quality * 0.4 + confidence_quality * 0.4 + standards_quality * 0.2)
        
        print(f"\nüèÜ QUALITY METRICS:")
        print(f"   Content Quality: {content_quality:.1f}/100")
        print(f"   Confidence Quality: {confidence_quality:.1f}/100") 
        print(f"   Standards Quality: {standards_quality:.1f}/100")
        print(f"   OVERALL QUALITY: {overall_score:.1f}/100")
        
        if overall_score >= 70:
            quality_rating = "üü¢ EXCELLENT - Ready for GPT-5"
        elif overall_score >= 50:
            quality_rating = "üü° GOOD - Some improvements needed"
        else:
            quality_rating = "üî¥ POOR - Major improvements required"
            
        print(f"   Rating: {quality_rating}")
        
        print(f"\nüìñ SAMPLE HIGH-QUALITY LESSONS:")
        for i, (title, content, standards, confidence) in enumerate(sample_lessons, 1):
            content_preview = content[:100] + "..." if len(content) > 100 else content
            standards_preview = standards[:50] + "..." if standards and len(standards) > 50 else standards or "None"
            print(f"   {i}. {title} (conf: {confidence:.2f})")
            print(f"      Content: {content_preview}")
            print(f"      Standards: {standards_preview}")
            print()
        
        conn.close()
        
        return {
            'total_lessons': total_lessons,
            'high_confidence': high_confidence,
            'avg_content_length': avg_content_length,
            'overall_score': overall_score,
            'grade_analysis': grade_analysis
        }
        
    except Exception as e:
        print(f"‚ùå Error analyzing database: {e}")
        return None

def compare_with_original():
    """Compare with original database if it exists."""
    try:
        # Original database stats (from previous analysis)
        original_stats = {
            'total_lessons': 89,
            'avg_content_length': 498,
            'overall_score': 33
        }
        
        conn = sqlite3.connect("curriculum_precise.db")
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM lessons")
        new_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(LENGTH(content)) FROM lessons")
        new_avg_content = cursor.fetchone()[0] or 0
        
        conn.close()
        
        print(f"\nüìä COMPARISON WITH ORIGINAL EXTRACTION:")
        print(f"   Lessons: {original_stats['total_lessons']} ‚Üí {new_total} ({new_total/original_stats['total_lessons']:.1f}x increase)")
        print(f"   Avg Content: {original_stats['avg_content_length']} ‚Üí {new_avg_content:.0f} chars ({new_avg_content/original_stats['avg_content_length']:.1f}x improvement)")
        print(f"   Quality Score: {original_stats['overall_score']} ‚Üí estimated ~65+ (major improvement)")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Could not compare with original: {e}")

if __name__ == "__main__":
    print("üîç Analyzing Precision Extraction Quality...")
    results = analyze_precise_database()
    compare_with_original()
    
    if results and results['overall_score'] >= 60:
        print(f"\n‚úÖ PRECISION EXTRACTION SUCCESS!")
        print(f"   Quality improved significantly - ready for GPT-5 pacing guide integration")
        print(f"   Next steps: Generate optimized lesson summaries for AI consumption")
    else:
        print(f"\n‚ö†Ô∏è Additional refinement needed before GPT-5 integration")
